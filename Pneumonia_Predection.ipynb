{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1863490a-a4ec-46b2-b7c4-e0d388da971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch \n",
    "import torch.onnx\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "214f05ef-8150-463b-a4e6-77ee101f0c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76f9f1f1-4b25-4dd1-8380-e9f0ad40339f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25] - Train Loss: 0.1833 - Val Loss: 1.4953 - Val Acc: 0.6875\n",
      "Validation loss decreased. Saving model...\n",
      "Epoch [2/25] - Train Loss: 0.1101 - Val Loss: 0.2636 - Val Acc: 0.8750\n",
      "Validation loss decreased. Saving model...\n",
      "Epoch [3/25] - Train Loss: 0.0934 - Val Loss: 1.9482 - Val Acc: 0.6250\n",
      "No improvement in validation loss. Patience: 1/5\n",
      "Epoch [4/25] - Train Loss: 0.0941 - Val Loss: 0.1112 - Val Acc: 1.0000\n",
      "Validation loss decreased. Saving model...\n",
      "Epoch [5/25] - Train Loss: 0.0819 - Val Loss: 0.3645 - Val Acc: 0.8750\n",
      "No improvement in validation loss. Patience: 1/5\n",
      "Epoch [6/25] - Train Loss: 0.0752 - Val Loss: 0.1334 - Val Acc: 0.8750\n",
      "No improvement in validation loss. Patience: 2/5\n",
      "Epoch [7/25] - Train Loss: 0.0538 - Val Loss: 0.2259 - Val Acc: 0.9375\n",
      "No improvement in validation loss. Patience: 3/5\n",
      "Epoch [8/25] - Train Loss: 0.0378 - Val Loss: 0.1187 - Val Acc: 0.9375\n",
      "No improvement in validation loss. Patience: 4/5\n",
      "Epoch [9/25] - Train Loss: 0.0415 - Val Loss: 0.2801 - Val Acc: 0.9375\n",
      "No improvement in validation loss. Patience: 5/5\n",
      "Early stopping triggered.\n",
      "\n",
      "Test Accuracy: 0.8478\n",
      "Precision: 0.8067\n",
      "Recall: 0.9949\n",
      "F1 Score: 0.8909\n",
      "Confusion Matrix:\n",
      " [[141  93]\n",
      " [  2 388]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.60      0.75       234\n",
      "           1       0.81      0.99      0.89       390\n",
      "\n",
      "    accuracy                           0.85       624\n",
      "   macro avg       0.90      0.80      0.82       624\n",
      "weighted avg       0.87      0.85      0.84       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class PneumoniaDataset(Dataset):\n",
    "    def __init__(self,root_dir,transform = None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for label in ['NORMAL', 'PNEUMONIA']:\n",
    "            class_dir = os.path.join(root_dir,label)\n",
    "            for image_name in os.listdir(class_dir):\n",
    "                if image_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                   self.image_paths.append(os.path.join(class_dir,image_name))\n",
    "                   self.labels.append(0 if label == 'NORMAL' else 1)\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "\n",
    "#data augmentation\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = PneumoniaDataset(root_dir='chest_xray/train',transform = train_transform)\n",
    "test_dataset = PneumoniaDataset(root_dir='chest_xray/test',transform = test_transform)\n",
    "val_dataset = PneumoniaDataset(root_dir='chest_xray/val',transform = test_transform)\n",
    "\n",
    "class_counts = [train_dataset.labels.count(0), train_dataset.labels.count(1)]\n",
    "class_weights = torch.tensor([1.0 / class_counts[0], 1.0 / class_counts[1]], device=device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size = 32,shuffle = True)\n",
    "test_loader = DataLoader(test_dataset,batch_size = 32,shuffle = False)\n",
    "val_loader = DataLoader(val_dataset,batch_size = 32,shuffle = False)\n",
    "\n",
    "\n",
    "model = models.resnet18(weights = models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(model.fc.in_features,2)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(),lr = 0.001)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.2, patience=2)\n",
    "\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.verbose = verbose\n",
    "        self.best_model = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None or val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = model.state_dict()\n",
    "            self.counter = 0\n",
    "            if self.verbose:\n",
    "                print(\"Validation loss decreased. Saving model...\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"No improvement in validation loss. Patience: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "\n",
    "num_epochs = 25\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "#train\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_labels = []\n",
    "    val_predictions = []\n",
    "\n",
    "    \n",
    "#validation\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs,labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "\n",
    "            _, predictions = torch.max(outputs,1)\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "            val_predictions.extend(predictions.cpu().numpy())\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_acc = accuracy_score(val_labels, val_predictions)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f} - Val Loss: {avg_val_loss:.4f} - Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    early_stopping(avg_val_loss, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "\n",
    "#getting the best model\n",
    "\n",
    "\n",
    "model.load_state_dict(early_stopping.best_model)\n",
    "\n",
    "model.eval()\n",
    "test_labels = []\n",
    "test_predictions = []\n",
    "\n",
    "#testing \n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs,1)\n",
    "\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "        test_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "#measuring the accuracy\n",
    "\n",
    "test_acc = accuracy_score(test_labels, test_predictions)\n",
    "test_precision = precision_score(test_labels, test_predictions)\n",
    "test_recall = recall_score(test_labels, test_predictions)\n",
    "test_f1 = f1_score(test_labels, test_predictions)\n",
    "\n",
    "\n",
    "print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall: {test_recall:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(test_labels, test_predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(test_labels, test_predictions))\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(),'pneumonia_detection_model.pth')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c6a830-7790-429a-99d0-c0930013b338",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()  \n",
    "\n",
    "dummy_input = torch.randn(1, 3, 224, 224, device=device)  \n",
    "\n",
    "onnx_path = \"pneumonia_model.onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    onnx_path,\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    ")\n",
    "\n",
    "print(f\" Model exported to ONNX format at '{onnx_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe25025-c3ce-45e3-9aa9-8469f791afbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
